{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1438,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import imblearn\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1439,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Reading dataset from csv file\n",
    "data=pd.read_csv(\"Creditcard_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1440,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>-0.572263</td>\n",
       "      <td>0.731748</td>\n",
       "      <td>1.541254</td>\n",
       "      <td>0.150506</td>\n",
       "      <td>1.108974</td>\n",
       "      <td>0.372152</td>\n",
       "      <td>1.084879</td>\n",
       "      <td>-0.146329</td>\n",
       "      <td>-0.274447</td>\n",
       "      <td>-0.663670</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.143508</td>\n",
       "      <td>-0.107582</td>\n",
       "      <td>-0.418263</td>\n",
       "      <td>-0.731029</td>\n",
       "      <td>0.877525</td>\n",
       "      <td>-0.364150</td>\n",
       "      <td>-0.177509</td>\n",
       "      <td>-0.256545</td>\n",
       "      <td>26.72</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>768</th>\n",
       "      <td>-1.296845</td>\n",
       "      <td>-0.511605</td>\n",
       "      <td>2.404726</td>\n",
       "      <td>-0.310762</td>\n",
       "      <td>-0.319551</td>\n",
       "      <td>-0.542842</td>\n",
       "      <td>-0.173310</td>\n",
       "      <td>0.260423</td>\n",
       "      <td>-1.202688</td>\n",
       "      <td>0.050584</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.071270</td>\n",
       "      <td>-0.161175</td>\n",
       "      <td>0.088496</td>\n",
       "      <td>0.285390</td>\n",
       "      <td>0.281069</td>\n",
       "      <td>-0.370130</td>\n",
       "      <td>0.043410</td>\n",
       "      <td>0.092318</td>\n",
       "      <td>80.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769</th>\n",
       "      <td>1.214170</td>\n",
       "      <td>0.210481</td>\n",
       "      <td>0.484651</td>\n",
       "      <td>0.479768</td>\n",
       "      <td>-0.261955</td>\n",
       "      <td>-0.527039</td>\n",
       "      <td>0.021782</td>\n",
       "      <td>-0.106888</td>\n",
       "      <td>-0.037631</td>\n",
       "      <td>-0.144073</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.224292</td>\n",
       "      <td>-0.594609</td>\n",
       "      <td>0.159877</td>\n",
       "      <td>0.091873</td>\n",
       "      <td>0.140964</td>\n",
       "      <td>0.227406</td>\n",
       "      <td>-0.017389</td>\n",
       "      <td>0.016030</td>\n",
       "      <td>5.98</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770</th>\n",
       "      <td>1.267030</td>\n",
       "      <td>-0.071114</td>\n",
       "      <td>0.037680</td>\n",
       "      <td>0.512683</td>\n",
       "      <td>0.242392</td>\n",
       "      <td>0.705212</td>\n",
       "      <td>-0.226582</td>\n",
       "      <td>0.109483</td>\n",
       "      <td>0.657565</td>\n",
       "      <td>-0.276918</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.164468</td>\n",
       "      <td>-0.177225</td>\n",
       "      <td>-0.222918</td>\n",
       "      <td>-1.245505</td>\n",
       "      <td>0.678360</td>\n",
       "      <td>0.525059</td>\n",
       "      <td>0.002920</td>\n",
       "      <td>-0.003333</td>\n",
       "      <td>12.36</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>771</th>\n",
       "      <td>1.153758</td>\n",
       "      <td>0.132273</td>\n",
       "      <td>0.382969</td>\n",
       "      <td>1.405063</td>\n",
       "      <td>-0.224287</td>\n",
       "      <td>-0.197295</td>\n",
       "      <td>0.020653</td>\n",
       "      <td>0.029260</td>\n",
       "      <td>0.412254</td>\n",
       "      <td>-0.103547</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.107809</td>\n",
       "      <td>-0.125231</td>\n",
       "      <td>-0.057041</td>\n",
       "      <td>0.073082</td>\n",
       "      <td>0.633977</td>\n",
       "      <td>-0.310685</td>\n",
       "      <td>0.033590</td>\n",
       "      <td>0.015250</td>\n",
       "      <td>13.79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>772 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1    1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "767 -0.572263  0.731748  1.541254  0.150506  1.108974  0.372152  1.084879   \n",
       "768 -1.296845 -0.511605  2.404726 -0.310762 -0.319551 -0.542842 -0.173310   \n",
       "769  1.214170  0.210481  0.484651  0.479768 -0.261955 -0.527039  0.021782   \n",
       "770  1.267030 -0.071114  0.037680  0.512683  0.242392  0.705212 -0.226582   \n",
       "771  1.153758  0.132273  0.382969  1.405063 -0.224287 -0.197295  0.020653   \n",
       "\n",
       "           V8        V9       V10  ...       V21       V22       V23  \\\n",
       "0    0.098698  0.363787  0.090794  ... -0.018307  0.277838 -0.110474   \n",
       "1    0.085102 -0.255425 -0.166974  ... -0.225775 -0.638672  0.101288   \n",
       "2    0.247676 -1.514654  0.207643  ...  0.247998  0.771679  0.909412   \n",
       "3    0.377436 -1.387024 -0.054952  ... -0.108300  0.005274 -0.190321   \n",
       "4   -0.270533  0.817739  0.753074  ... -0.009431  0.798278 -0.137458   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "767 -0.146329 -0.274447 -0.663670  ... -0.143508 -0.107582 -0.418263   \n",
       "768  0.260423 -1.202688  0.050584  ... -0.071270 -0.161175  0.088496   \n",
       "769 -0.106888 -0.037631 -0.144073  ... -0.224292 -0.594609  0.159877   \n",
       "770  0.109483  0.657565 -0.276918  ... -0.164468 -0.177225 -0.222918   \n",
       "771  0.029260  0.412254 -0.103547  ... -0.107809 -0.125231 -0.057041   \n",
       "\n",
       "          V24       V25       V26       V27       V28  Amount  Class  \n",
       "0    0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1   -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69      1  \n",
       "2   -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3   -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4    0.141267 -0.206010  0.502292  0.219422  0.215153   69.99      0  \n",
       "..        ...       ...       ...       ...       ...     ...    ...  \n",
       "767 -0.731029  0.877525 -0.364150 -0.177509 -0.256545   26.72      0  \n",
       "768  0.285390  0.281069 -0.370130  0.043410  0.092318   80.00      0  \n",
       "769  0.091873  0.140964  0.227406 -0.017389  0.016030    5.98      0  \n",
       "770 -1.245505  0.678360  0.525059  0.002920 -0.003333   12.36      0  \n",
       "771  0.073082  0.633977 -0.310685  0.033590  0.015250   13.79      0  \n",
       "\n",
       "[772 rows x 30 columns]"
      ]
     },
     "execution_count": 1440,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##checking size of dataset\n",
    "data=data.drop(['Time'],axis=1)\n",
    "data.shape\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1441,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 1441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Finding no of classes\n",
    "classes=data['Class'].unique()\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1442,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(763, 30)"
      ]
     },
     "execution_count": 1442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Finding no of rows with class 0 \n",
    "data[data['Class']==0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1443,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 30)"
      ]
     },
     "execution_count": 1443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Finding no of rows with class1\n",
    "data[data['Class']==1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1444,
   "metadata": {},
   "outputs": [],
   "source": [
    "##separating columns and target\n",
    "columns=data.columns.tolist()\n",
    "columns=[c for c in columns if c not in [\"Class\"]]\n",
    "target=\"Class\"\n",
    "x=data[columns]\n",
    "y=data[target]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balancing data using smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1445,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Balancing data using smote\n",
    "from imblearn.over_sampling import SMOTE\n",
    "oversample = SMOTE()\n",
    "X, Y = oversample.fit_resample(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1446,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.620000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.690000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.660000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.500000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.990000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1521</th>\n",
       "      <td>0.771110</td>\n",
       "      <td>0.360905</td>\n",
       "      <td>0.621325</td>\n",
       "      <td>0.579989</td>\n",
       "      <td>-0.074970</td>\n",
       "      <td>-1.032746</td>\n",
       "      <td>0.262359</td>\n",
       "      <td>-0.192586</td>\n",
       "      <td>-0.004133</td>\n",
       "      <td>-0.347366</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.209150</td>\n",
       "      <td>-0.585780</td>\n",
       "      <td>0.042526</td>\n",
       "      <td>0.349612</td>\n",
       "      <td>0.254766</td>\n",
       "      <td>-0.026869</td>\n",
       "      <td>-0.041327</td>\n",
       "      <td>-0.003827</td>\n",
       "      <td>2.315457</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1522</th>\n",
       "      <td>0.282194</td>\n",
       "      <td>0.322810</td>\n",
       "      <td>0.842159</td>\n",
       "      <td>0.334237</td>\n",
       "      <td>0.448939</td>\n",
       "      <td>-0.433639</td>\n",
       "      <td>0.332195</td>\n",
       "      <td>-0.018608</td>\n",
       "      <td>-0.206805</td>\n",
       "      <td>-0.341961</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.100423</td>\n",
       "      <td>-0.243881</td>\n",
       "      <td>-0.052867</td>\n",
       "      <td>-0.028652</td>\n",
       "      <td>0.263265</td>\n",
       "      <td>-0.122874</td>\n",
       "      <td>-0.049947</td>\n",
       "      <td>-0.045560</td>\n",
       "      <td>1.964825</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523</th>\n",
       "      <td>-0.911776</td>\n",
       "      <td>0.280098</td>\n",
       "      <td>0.851619</td>\n",
       "      <td>-0.304583</td>\n",
       "      <td>0.876056</td>\n",
       "      <td>-0.043908</td>\n",
       "      <td>0.281510</td>\n",
       "      <td>0.140114</td>\n",
       "      <td>-0.043387</td>\n",
       "      <td>-0.101180</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.156373</td>\n",
       "      <td>-0.278681</td>\n",
       "      <td>-0.073488</td>\n",
       "      <td>-0.751466</td>\n",
       "      <td>-0.815972</td>\n",
       "      <td>0.165078</td>\n",
       "      <td>-0.081914</td>\n",
       "      <td>-0.103532</td>\n",
       "      <td>0.995437</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1524</th>\n",
       "      <td>-0.150965</td>\n",
       "      <td>0.516781</td>\n",
       "      <td>0.740817</td>\n",
       "      <td>0.130138</td>\n",
       "      <td>0.855092</td>\n",
       "      <td>-0.006799</td>\n",
       "      <td>0.426905</td>\n",
       "      <td>0.073142</td>\n",
       "      <td>-0.127323</td>\n",
       "      <td>-0.239466</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.085032</td>\n",
       "      <td>-0.233280</td>\n",
       "      <td>0.059357</td>\n",
       "      <td>-0.971927</td>\n",
       "      <td>-0.990126</td>\n",
       "      <td>-0.043199</td>\n",
       "      <td>0.156406</td>\n",
       "      <td>0.150403</td>\n",
       "      <td>0.992241</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1525</th>\n",
       "      <td>-1.006457</td>\n",
       "      <td>0.364791</td>\n",
       "      <td>1.687556</td>\n",
       "      <td>0.101516</td>\n",
       "      <td>0.961962</td>\n",
       "      <td>-0.842097</td>\n",
       "      <td>0.820040</td>\n",
       "      <td>-0.127851</td>\n",
       "      <td>-0.126107</td>\n",
       "      <td>-0.525619</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042577</td>\n",
       "      <td>0.235602</td>\n",
       "      <td>-0.258345</td>\n",
       "      <td>0.325157</td>\n",
       "      <td>0.320902</td>\n",
       "      <td>-0.386731</td>\n",
       "      <td>-0.127720</td>\n",
       "      <td>-0.150693</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1526 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0    -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1     1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2    -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3    -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4    -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1521  0.771110  0.360905  0.621325  0.579989 -0.074970 -1.032746  0.262359   \n",
       "1522  0.282194  0.322810  0.842159  0.334237  0.448939 -0.433639  0.332195   \n",
       "1523 -0.911776  0.280098  0.851619 -0.304583  0.876056 -0.043908  0.281510   \n",
       "1524 -0.150965  0.516781  0.740817  0.130138  0.855092 -0.006799  0.426905   \n",
       "1525 -1.006457  0.364791  1.687556  0.101516  0.961962 -0.842097  0.820040   \n",
       "\n",
       "            V8        V9       V10  ...       V21       V22       V23  \\\n",
       "0     0.098698  0.363787  0.090794  ... -0.018307  0.277838 -0.110474   \n",
       "1     0.085102 -0.255425 -0.166974  ... -0.225775 -0.638672  0.101288   \n",
       "2     0.247676 -1.514654  0.207643  ...  0.247998  0.771679  0.909412   \n",
       "3     0.377436 -1.387024 -0.054952  ... -0.108300  0.005274 -0.190321   \n",
       "4    -0.270533  0.817739  0.753074  ... -0.009431  0.798278 -0.137458   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "1521 -0.192586 -0.004133 -0.347366  ... -0.209150 -0.585780  0.042526   \n",
       "1522 -0.018608 -0.206805 -0.341961  ... -0.100423 -0.243881 -0.052867   \n",
       "1523  0.140114 -0.043387 -0.101180  ... -0.156373 -0.278681 -0.073488   \n",
       "1524  0.073142 -0.127323 -0.239466  ... -0.085032 -0.233280  0.059357   \n",
       "1525 -0.127851 -0.126107 -0.525619  ...  0.042577  0.235602 -0.258345   \n",
       "\n",
       "           V24       V25       V26       V27       V28      Amount  Class  \n",
       "0     0.066928  0.128539 -0.189115  0.133558 -0.021053  149.620000      0  \n",
       "1    -0.339846  0.167170  0.125895 -0.008983  0.014724    2.690000      1  \n",
       "2    -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.660000      0  \n",
       "3    -1.175575  0.647376 -0.221929  0.062723  0.061458  123.500000      0  \n",
       "4     0.141267 -0.206010  0.502292  0.219422  0.215153   69.990000      0  \n",
       "...        ...       ...       ...       ...       ...         ...    ...  \n",
       "1521  0.349612  0.254766 -0.026869 -0.041327 -0.003827    2.315457      1  \n",
       "1522 -0.028652  0.263265 -0.122874 -0.049947 -0.045560    1.964825      1  \n",
       "1523 -0.751466 -0.815972  0.165078 -0.081914 -0.103532    0.995437      1  \n",
       "1524 -0.971927 -0.990126 -0.043199  0.156406  0.150403    0.992241      1  \n",
       "1525  0.325157  0.320902 -0.386731 -0.127720 -0.150693    1.000000      1  \n",
       "\n",
       "[1526 rows x 30 columns]"
      ]
     },
     "execution_count": 1446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newdata=pd.DataFrame(X)\n",
    "newdata['Class']=Y\n",
    "newdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1447,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1526, 30)"
      ]
     },
     "execution_count": 1447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newdata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1448,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(763, 30)"
      ]
     },
     "execution_count": 1448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newdata[newdata['Class']==0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1449,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(763, 30)"
      ]
     },
     "execution_count": 1449,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newdata[newdata['Class']==1].shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1450,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384\n"
     ]
    }
   ],
   "source": [
    "##Random sampling\n",
    "##size of sample\n",
    "z=1.96\n",
    "p=0.5\n",
    "E=0.05\n",
    "n=math.floor((pow(z,2)*p*(1-p))/pow(E,2))\n",
    "print(n)\n",
    "rand=newdata.sample(n)\n",
    "rand_columns=rand.columns.tolist()\n",
    "rand_columns=[c for c in rand_columns if c not in [\"Class\"]]\n",
    "rand_target=\"Class\"\n",
    "new_xrand=rand[rand_columns]\n",
    "new_yrand=rand[rand_target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1451,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Splitting data into train and test\n",
    "X_trainrand, X_testrand, y_trainrand, y_testrand = train_test_split(new_xrand,new_yrand, test_size=0.33, random_state=42)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratified sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1452,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Stratified sampling\n",
    "z=1.96\n",
    "p=0.5\n",
    "E=0.05\n",
    "S=2\n",
    "n=math.floor((pow(z,2)*p*(1-p))/pow((E/S),2))\n",
    "class0=newdata[newdata['Class']==0]\n",
    "class1=newdata[newdata['Class']==1]\n",
    "c0=class0.sample(math.floor(n/4))\n",
    "c1=class1.sample(math.floor(n/4))\n",
    "c=[c0,c1]\n",
    "stratdata=pd.concat(c,ignore_index=False)\n",
    "strat_columns=stratdata.columns.tolist()\n",
    "strat_columns=[c for c in strat_columns if c not in [\"Class\"]]\n",
    "strat_target=\"Class\"\n",
    "new_xstrat=stratdata[strat_columns]\n",
    "new_ystrat=stratdata[strat_target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1453,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Splitting data into train and test\n",
    "X_trainstrat, X_teststrat, y_trainstrat, y_teststrat = train_test_split(new_xstrat,new_ystrat, test_size=0.33, random_state=42)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cluster sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1454,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterList = []\n",
    "s= pd.DataFrame()\n",
    "for i in range(10) :\n",
    "    cluster = newdata.sample(n=150,ignore_index=True,random_state=i)\n",
    "    # print(\"cluster : \",cluster.shape)\n",
    "    clusterList.append(cluster)\n",
    "for i in range(5) :\n",
    "    s= pd.concat([s,clusterList[random.randint(1,5)]])  \n",
    "\n",
    "clust_columns=s.columns.tolist()\n",
    "clust_columns=[c for c in rand_columns if c not in [\"Class\"]]\n",
    "clust_target=\"Class\"\n",
    "new_xclust=s[clust_columns]\n",
    "new_yclust=s[clust_target] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1455,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Splitting data into train and test\n",
    "X_trainclust, X_testclust, y_trainclust, y_testclust = train_test_split(new_xclust,new_yclust, test_size=0.33, random_state=42)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### systematic sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1456,
   "metadata": {},
   "outputs": [],
   "source": [
    "##systematic sampling\n",
    "N=1526\n",
    "E=0.05\n",
    "n =math.floor( N /(1 + (N*pow(E,2))))\n",
    "# print(n)\n",
    "def systematic_sampling(df, step):\n",
    "    indexes = np.arange(0, len(df), step=step)\n",
    "    systematic_sample = df.iloc[indexes]\n",
    "    return systematic_sample\n",
    "\n",
    "systsample = systematic_sampling(newdata,(1526/n))\n",
    "syst_columns=systsample.columns.tolist()\n",
    "syst_columns=[c for c in syst_columns if c not in [\"Class\"]]\n",
    "syst_target=\"Class\"\n",
    "new_xsyst=systsample[syst_columns]\n",
    "new_ysyst=systsample[syst_target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1457,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Splitting data into train and test\n",
    "X_trainsyst, X_testsyst, y_trainsyst, y_testsyst = train_test_split(new_xsyst,new_ysyst, test_size=0.33, random_state=42)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multistage sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1458,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Multistage sampling\n",
    "z=1.96\n",
    "p=0.5\n",
    "E=0.05\n",
    "n=math.floor((pow(z,2)*p*(1-p))/pow(E,2))\n",
    "classes = np.random.choice([0,1], size=n)\n",
    "multisample = newdata[newdata['Class'].isin(classes)].sample(n, replace=True)\n",
    "multi_columns=multisample.columns.tolist()\n",
    "multi_columns=[c for c in multi_columns if c not in [\"Class\"]]\n",
    "multi_target=\"Class\"\n",
    "new_xstage=multisample[multi_columns]\n",
    "new_ystage=multisample[multi_target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1459,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Splitting data into train and test\n",
    "X_trainstage, X_teststage, y_trainstage, y_teststage = train_test_split(new_xstage,new_ystage, test_size=0.33, random_state=42)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1460,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on random sample:  0.8740157480314961\n",
      "Accuracy on stratified sample:  0.9645669291338582\n",
      "Accuracy on cluster sample:  0.9516129032258065\n",
      "Accuracy on systematic sample:  0.8952380952380953\n",
      "Accuracy on multistage sample:  0.9448818897637795\n"
     ]
    }
   ],
   "source": [
    "##Decision tree\n",
    "##random sampling\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clfrand = DecisionTreeClassifier()\n",
    "clfrand.fit(X_trainrand,y_trainrand)\n",
    "y_predrand = clfrand.predict(X_testrand)\n",
    "print(\"Accuracy on random sample: \",metrics.accuracy_score(y_testrand, y_predrand))\n",
    "treerand=metrics.accuracy_score(y_testrand, y_predrand)\n",
    "\n",
    "##stratified sampling\n",
    "clfstrat = DecisionTreeClassifier()\n",
    "clfstrat.fit(X_trainstrat,y_trainstrat)\n",
    "y_predstrat = clfstrat.predict(X_teststrat)\n",
    "print(\"Accuracy on stratified sample: \",metrics.accuracy_score(y_teststrat, y_predstrat))\n",
    "treestrat=metrics.accuracy_score(y_teststrat, y_predstrat)\n",
    "\n",
    "##cluster sampling\n",
    "clfclust = DecisionTreeClassifier()\n",
    "clfclust.fit(X_trainclust,y_trainclust)\n",
    "y_predclust = clfclust.predict(X_testclust)\n",
    "print(\"Accuracy on cluster sample: \",metrics.accuracy_score(y_testclust, y_predclust))\n",
    "treeclust=metrics.accuracy_score(y_testclust, y_predclust)\n",
    "\n",
    "##systematic sampling\n",
    "\n",
    "clfsyst = DecisionTreeClassifier()\n",
    "clfsyst.fit(X_trainsyst,y_trainsyst)\n",
    "y_predsyst = clfsyst.predict(X_testsyst)\n",
    "print(\"Accuracy on systematic sample: \",metrics.accuracy_score(y_testsyst, y_predsyst))\n",
    "treesyst=metrics.accuracy_score(y_testsyst, y_predsyst)\n",
    "\n",
    "##multistage sampling\n",
    "clfmulti = DecisionTreeClassifier()\n",
    "clfmulti.fit(X_trainstage,y_trainstage)\n",
    "y_predstage = clfmulti.predict(X_teststage)\n",
    "print(\"Accuracy on multistage sample: \",metrics.accuracy_score(y_teststage, y_predstage))\n",
    "treestage=metrics.accuracy_score(y_teststage, y_predstage)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive bayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1461,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on random sample:  0.7244094488188977\n",
      "Accuracy on stratified sample:  0.7165354330708661\n",
      "Accuracy on cluster sample:  0.7782258064516129\n",
      "Accuracy on systematic sample:  0.6952380952380952\n",
      "Accuracy on  multistage sample:  0.7637795275590551\n"
     ]
    }
   ],
   "source": [
    "##Naive bayes \n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "##random sampling\n",
    "gnbrand = GaussianNB()\n",
    "gnbrand.fit(X_trainrand,y_trainrand)\n",
    "y_predrand = gnbrand.predict(X_testrand)\n",
    "print(\"Accuracy on random sample: \",metrics.accuracy_score(y_testrand, y_predrand))\n",
    "naiverand=metrics.accuracy_score(y_testrand, y_predrand)\n",
    "\n",
    "##stratified sampling\n",
    "gnbstrat = GaussianNB()\n",
    "gnbstrat.fit(X_trainstrat,y_trainstrat)\n",
    "y_predstrat = gnbstrat.predict(X_teststrat)\n",
    "print(\"Accuracy on stratified sample: \",metrics.accuracy_score(y_teststrat, y_predstrat))\n",
    "naivestrat=metrics.accuracy_score(y_teststrat, y_predstrat)\n",
    "\n",
    "##cluster sampling\n",
    "gnbclust = GaussianNB()\n",
    "gnbclust.fit(X_trainclust,y_trainclust)\n",
    "y_predclust = gnbclust.predict(X_testclust)\n",
    "print(\"Accuracy on cluster sample: \",metrics.accuracy_score(y_testclust, y_predclust))\n",
    "naiveclust=metrics.accuracy_score(y_testclust, y_predclust)\n",
    "\n",
    "\n",
    "##systematic sampling\n",
    "\n",
    "gnbsyst = GaussianNB()\n",
    "gnbsyst.fit(X_trainsyst,y_trainsyst)\n",
    "y_predsyst = gnbsyst.predict(X_testsyst)\n",
    "print(\"Accuracy on systematic sample: \",metrics.accuracy_score(y_testsyst, y_predsyst))\n",
    "naivesyst=metrics.accuracy_score(y_testsyst, y_predsyst)\n",
    "\n",
    "##multistage sampling\n",
    "gnbmulti = GaussianNB()\n",
    "gnbmulti.fit(X_trainstage,y_trainstage)\n",
    "y_predstage = gnbmulti.predict(X_teststage)\n",
    "print(\"Accuracy on  multistage sample: \",metrics.accuracy_score(y_teststage, y_predstage))\n",
    "naivestage=metrics.accuracy_score(y_teststage, y_predstage)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1462,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on random sample:  0.6377952755905512\n",
      "Accuracy on stratified sample:  0.5748031496062992\n",
      "Accuracy on cluster sample:  0.5846774193548387\n",
      "Accuracy on systematic sample:  0.7904761904761904\n",
      "Accuracy on  multistage sample:  0.6456692913385826\n"
     ]
    }
   ],
   "source": [
    "##Logistic regression \n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "##random sampling\n",
    "logrand = linear_model.LogisticRegression()\n",
    "sc_x = StandardScaler()\n",
    "X_trainrand = sc_x.fit_transform(X_trainrand) \n",
    "# X_testrand = sc_x.transform(X_testrand)\n",
    "logrand.fit(X_trainrand,y_trainrand)\n",
    "y_predrand = logrand.predict(X_testrand)\n",
    "print(\"Accuracy on random sample: \",metrics.accuracy_score(y_testrand, y_predrand))\n",
    "logicrand=metrics.accuracy_score(y_testrand, y_predrand)\n",
    "\n",
    "##stratified sampling\n",
    "logstrat = linear_model.LogisticRegression()\n",
    "sc_x = StandardScaler()\n",
    "X_trainstrat = sc_x.fit_transform(X_trainstrat) \n",
    "# X_teststrat = sc_x.transform(X_teststrat)\n",
    "logstrat.fit(X_trainstrat,y_trainstrat)\n",
    "y_predstrat = logstrat.predict(X_teststrat)\n",
    "print(\"Accuracy on stratified sample: \",metrics.accuracy_score(y_teststrat, y_predstrat))\n",
    "logicstrat=metrics.accuracy_score(y_teststrat, y_predstrat)\n",
    "\n",
    "##cluster sampling\n",
    "logclust = linear_model.LogisticRegression()\n",
    "sc_x = StandardScaler()\n",
    "X_trainclust = sc_x.fit_transform(X_trainclust) \n",
    "# X_testclust = sc_x.transform(X_testclust)\n",
    "logclust.fit(X_trainclust,y_trainclust)\n",
    "y_predclust = logclust.predict(X_testclust)\n",
    "print(\"Accuracy on cluster sample: \",metrics.accuracy_score(y_testclust, y_predclust))\n",
    "logicclust=metrics.accuracy_score(y_testclust, y_predclust)\n",
    "\n",
    "##systematic sampling\n",
    "\n",
    "logsyst = linear_model.LogisticRegression()\n",
    "sc_x = StandardScaler()\n",
    "X_trainsyst = sc_x.fit_transform(X_trainsyst) \n",
    "# X_testsyst = sc_x.transform(X_testsyst)\n",
    "logsyst.fit(X_trainsyst,y_trainsyst)\n",
    "y_predsyst = logsyst.predict(X_testsyst)\n",
    "print(\"Accuracy on systematic sample: \",metrics.accuracy_score(y_testsyst, y_predsyst))\n",
    "logicsyst=metrics.accuracy_score(y_testsyst, y_predsyst)\n",
    "\n",
    "##multistage sampling\n",
    "logmulti = linear_model.LogisticRegression()\n",
    "sc_x = StandardScaler()\n",
    "X_trainstage = sc_x.fit_transform(X_trainstage) \n",
    "# X_teststage = sc_x.transform(X_teststage)\n",
    "logmulti.fit(X_trainstage,y_trainstage)\n",
    "y_predstage = logmulti.predict(X_teststage)\n",
    "print(\"Accuracy on  multistage sample: \",metrics.accuracy_score(y_teststage, y_predstage))\n",
    "logicstage=metrics.accuracy_score(y_teststage, y_predstage)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1463,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on random sample:  0.8503937007874016\n",
      "Accuracy on stratified sample:  0.905511811023622\n",
      "Accuracy on cluster sample:  0.8709677419354839\n",
      "Accuracy on systematic sample:  0.8952380952380953\n",
      "Accuracy on  multistage sample:  0.6456692913385826\n"
     ]
    }
   ],
   "source": [
    "##Knn\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "##random sampling\n",
    "knnrand = KNeighborsClassifier(n_neighbors=5)\n",
    "sc_x = StandardScaler()\n",
    "X_trainrand = sc_x.fit_transform(X_trainrand) \n",
    "# X_testrand = sc_x.transform(X_testrand)\n",
    "knnrand.fit(X_trainrand,y_trainrand)\n",
    "y_predrand = knnrand.predict(X_testrand)\n",
    "print(\"Accuracy on random sample: \",metrics.accuracy_score(y_testrand, y_predrand))\n",
    "knrand=metrics.accuracy_score(y_testrand, y_predrand)\n",
    "\n",
    "##stratified sampling\n",
    "knnstrat = KNeighborsClassifier(n_neighbors=5)\n",
    "sc_x = StandardScaler()\n",
    "X_trainstrat = sc_x.fit_transform(X_trainstrat) \n",
    "# X_teststrat = sc_x.transform(X_teststrat)\n",
    "knnstrat.fit(X_trainstrat,y_trainstrat)\n",
    "y_predstrat = knnstrat.predict(X_teststrat)\n",
    "print(\"Accuracy on stratified sample: \",metrics.accuracy_score(y_teststrat, y_predstrat))\n",
    "knstrat=metrics.accuracy_score(y_teststrat, y_predstrat)\n",
    "\n",
    "##cluster sampling\n",
    "knnclust = KNeighborsClassifier(n_neighbors=5)\n",
    "sc_x = StandardScaler()\n",
    "X_trainclust = sc_x.fit_transform(X_trainclust) \n",
    "# X_testclust = sc_x.transform(X_testclust)\n",
    "knnclust.fit(X_trainclust,y_trainclust)\n",
    "y_predclust = knnclust.predict(X_testclust)\n",
    "print(\"Accuracy on cluster sample: \",metrics.accuracy_score(y_testclust, y_predclust))\n",
    "knclust=metrics.accuracy_score(y_testclust, y_predclust)\n",
    "\n",
    "##systematic sampling\n",
    "\n",
    "knnsyst = KNeighborsClassifier(n_neighbors=5)\n",
    "sc_x = StandardScaler()\n",
    "X_trainsyst = sc_x.fit_transform(X_trainsyst) \n",
    "# X_testsyst = sc_x.transform(X_testsyst)\n",
    "knnsyst.fit(X_trainsyst,y_trainsyst)\n",
    "y_predsyst = knnsyst.predict(X_testsyst)\n",
    "print(\"Accuracy on systematic sample: \",metrics.accuracy_score(y_testsyst, y_predsyst))\n",
    "knsyst=metrics.accuracy_score(y_testsyst, y_predsyst)\n",
    "\n",
    "##multistage sampling\n",
    "knnmulti = linear_model.LogisticRegression()\n",
    "sc_x = StandardScaler()\n",
    "X_trainstage = sc_x.fit_transform(X_trainstage) \n",
    "# X_teststage = sc_x.transform(X_teststage)\n",
    "knnmulti.fit(X_trainstage,y_trainstage)\n",
    "y_predstage = knnmulti.predict(X_teststage)\n",
    "print(\"Accuracy on  multistage sample: \",metrics.accuracy_score(y_teststage, y_predstage))\n",
    "knstage=metrics.accuracy_score(y_teststage, y_predstage)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1464,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on random sample:  0.44881889763779526\n",
      "Accuracy on stratified sample:  0.5354330708661418\n",
      "Accuracy on cluster sample:  0.4838709677419355\n",
      "Accuracy on systematic sample:  0.7523809523809524\n",
      "Accuracy on  multistage sample:  0.49606299212598426\n"
     ]
    }
   ],
   "source": [
    "##SVM\n",
    "from sklearn.svm import SVC \n",
    "##random sampling\n",
    "svrand = SVC(kernel='linear')\n",
    "svrand.fit(X_trainrand,y_trainrand)\n",
    "y_predrand = svrand.predict(X_testrand)\n",
    "print(\"Accuracy on random sample: \",metrics.accuracy_score(y_testrand, y_predrand))\n",
    "svmrand=metrics.accuracy_score(y_testrand, y_predrand)\n",
    "\n",
    "##stratified sampling\n",
    "svstrat = SVC(kernel='linear')\n",
    "svstrat.fit(X_trainstrat,y_trainstrat)\n",
    "y_predstrat = svstrat.predict(X_teststrat)\n",
    "print(\"Accuracy on stratified sample: \",metrics.accuracy_score(y_teststrat, y_predstrat))\n",
    "svmstrat=metrics.accuracy_score(y_teststrat, y_predstrat)\n",
    "\n",
    "##cluster sampling\n",
    "svclust = SVC(kernel='linear')\n",
    "svclust.fit(X_trainclust,y_trainclust)\n",
    "y_predclust = svclust.predict(X_testclust)\n",
    "print(\"Accuracy on cluster sample: \",metrics.accuracy_score(y_testclust, y_predclust))\n",
    "svmclust=metrics.accuracy_score(y_testclust, y_predclust)\n",
    "\n",
    "##systematic sampling\n",
    "\n",
    "svsyst = SVC(kernel='linear')\n",
    "svsyst.fit(X_trainsyst,y_trainsyst)\n",
    "y_predsyst = svsyst.predict(X_testsyst)\n",
    "print(\"Accuracy on systematic sample: \",metrics.accuracy_score(y_testsyst, y_predsyst))\n",
    "svmsyst=metrics.accuracy_score(y_testsyst, y_predsyst)\n",
    "\n",
    "##multistage sampling\n",
    "svmulti = SVC(kernel='linear')\n",
    "svmulti.fit(X_trainstage,y_trainstage)\n",
    "y_predstage = svmulti.predict(X_teststage)\n",
    "print(\"Accuracy on  multistage sample: \",metrics.accuracy_score(y_teststage, y_predstage))\n",
    "svmstage=metrics.accuracy_score(y_teststage, y_predstage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1465,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Randomsample</th>\n",
       "      <th>stratifiedsample</th>\n",
       "      <th>clusteringsample</th>\n",
       "      <th>systematicsample</th>\n",
       "      <th>multistagesample</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DecisionTree</th>\n",
       "      <td>0.874016</td>\n",
       "      <td>0.964567</td>\n",
       "      <td>0.951613</td>\n",
       "      <td>0.895238</td>\n",
       "      <td>0.944882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaiveBayes</th>\n",
       "      <td>0.724409</td>\n",
       "      <td>0.716535</td>\n",
       "      <td>0.778226</td>\n",
       "      <td>0.695238</td>\n",
       "      <td>0.763780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logisticregression</th>\n",
       "      <td>0.637795</td>\n",
       "      <td>0.574803</td>\n",
       "      <td>0.584677</td>\n",
       "      <td>0.790476</td>\n",
       "      <td>0.645669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.850394</td>\n",
       "      <td>0.905512</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.895238</td>\n",
       "      <td>0.645669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.448819</td>\n",
       "      <td>0.535433</td>\n",
       "      <td>0.483871</td>\n",
       "      <td>0.752381</td>\n",
       "      <td>0.496063</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Randomsample  stratifiedsample  clusteringsample  \\\n",
       "DecisionTree            0.874016          0.964567          0.951613   \n",
       "NaiveBayes              0.724409          0.716535          0.778226   \n",
       "Logisticregression      0.637795          0.574803          0.584677   \n",
       "KNN                     0.850394          0.905512          0.870968   \n",
       "SVM                     0.448819          0.535433          0.483871   \n",
       "\n",
       "                    systematicsample  multistagesample  \n",
       "DecisionTree                0.895238          0.944882  \n",
       "NaiveBayes                  0.695238          0.763780  \n",
       "Logisticregression          0.790476          0.645669  \n",
       "KNN                         0.895238          0.645669  \n",
       "SVM                         0.752381          0.496063  "
      ]
     },
     "execution_count": 1465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "Randomsample=[treerand,treestrat,treeclust,treesyst,treestage]\n",
    "stratifiedsample=[naiverand,naivestrat,naiveclust,naivesyst,naivestage]\n",
    "clusteringsample=[logicrand,logicstrat,logicclust,logicsyst,logicstage]\n",
    "systematicsample=[knrand,knstrat,knclust,knsyst,knstage]\n",
    "multistagesample=[svmrand,svmstrat,svmclust,svmsyst,svmstage]\n",
    "\n",
    "sampletech=[Randomsample,stratifiedsample,clusteringsample,systematicsample,multistagesample]\n",
    "Finalaccuracy=pd.DataFrame(sampletech,columns=['Randomsample','stratifiedsample','clusteringsample','systematicsample','multistagesample'])\n",
    "Finalaccuracy.index = ['DecisionTree', 'NaiveBayes', 'Logisticregression','KNN','SVM']\n",
    "Finalaccuracy\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a02443d8fd7bc9ff0ff40876e4540a355a33fc1fba757f99e1ed25ebd62a81ca"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
